import cv2
from aiortc import VideoStreamTrack
import asyncio
import openai
import base64
import time
import json
import re
from rich.console import Console
import os

from dotenv import load_dotenv
from openai import OpenAI


# Cargar variables de entorno desde el archivo .env
load_dotenv()

# Crear cliente de OpenAI
# AsegÃºrate de tener las variables de entorno ENDPOINT_URL y API_KEY configuradas
client = OpenAI(
    base_url=os.getenv("ENDPOINT_URL"),
    api_key=os.getenv("API_KEY")
)

console = Console()

class GestureAnalysisTrack(VideoStreamTrack):
    """
    Track de video que analiza gestos en tiempo real usando OpenAI Vision API
    """
    
    def __init__(self, track, peer_connection_id, data_channel=None):
        super().__init__()
        self.track = track
        self.peer_connection_id = peer_connection_id
        self.data_channel = data_channel
        self.last_analysis_time = 0
        self.analysis_interval = 5.0  # Analizar cada 5 segundos inicialmente
        self.analysis_enabled = False  # Inicia desactivado
        self.confidence_threshold = 60  # Reducir umbral para detectar mÃ¡s gestos
        
        console.log(f"ğŸ¤ GestureAnalysisTrack creado para {peer_connection_id} - Canal: {'âœ…' if data_channel else 'âŒ'}")
        console.log(f"ğŸ¤ ConfiguraciÃ³n inicial: intervalo={self.analysis_interval}s, umbral={self.confidence_threshold}%")
        
    async def recv(self):
        """Recibe frame y opcionalmente lo analiza"""
        frame = await self.track.recv()
        
        # Solo analizar si estÃ¡ habilitado
        if self.analysis_enabled:
            current_time = time.time()
            if current_time - self.last_analysis_time >= self.analysis_interval:
                self.last_analysis_time = current_time
                console.log(f"ğŸ” Frame disponible para anÃ¡lisis - {self.peer_connection_id} (habilitado: {self.analysis_enabled})")
                # Analizar de forma asÃ­ncrona para no bloquear el video
                asyncio.create_task(self.analyze_frame(frame))
        
        return frame
    
    async def analyze_frame(self, frame):
        """Analiza un frame para detectar gestos"""
        try:
            console.log(f"ğŸ” Iniciando anÃ¡lisis de frame para {self.peer_connection_id}")
            
            # Convertir frame a imagen BGR
            img = frame.to_ndarray(format="bgr24")
            console.log(f"ğŸ“ Dimensiones del frame: {img.shape}")
            
            # Redimensionar para optimizar (opcional)
            height, width = img.shape[:2]
            if width > 640:
                scale = 640 / width
                new_width = int(width * scale)
                new_height = int(height * scale)
                img = cv2.resize(img, (new_width, new_height))
                console.log(f"ğŸ“ Frame redimensionado a: {new_width}x{new_height}")
            
            # Convertir a JPEG y base64
            _, buffer = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 80])
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            console.log(f"ğŸ“¸ Frame convertido a base64 ({len(img_base64)} caracteres)")
            
            # Analizar con OpenAI
            console.log(f"ğŸ¤– Enviando a OpenAI para anÃ¡lisis...")
            result = await self.analyze_with_openai(img_base64)
            
            # Solo reportar si supera el umbral de confianza
            if result.get('gesture') and result.get('confidence', 0) >= self.confidence_threshold:
                console.log(f"âœ… Gesto detectado: {result}")
                await self.send_gesture_result(result)
            else:
                console.log(f"âšª No se detectÃ³ gesto vÃ¡lido o baja confianza: {result}")
                
        except Exception as e:
            console.log(f"âŒ Error analizando frame para {self.peer_connection_id}: {e}")
            import traceback
            console.log(f"ğŸ“ Traceback: {traceback.format_exc()}")
    
    async def analyze_with_openai(self, image_base64):
        """EnvÃ­a imagen a OpenAI Vision API para anÃ¡lisis de gestos"""
        try:
            console.log(f"ğŸ§  Modelo para analizar {os.getenv('MODEL')}")
            console.log(f"ğŸ§  Endpoint para analizar {os.getenv('ENDPOINT_URL')}")
            
            
            # Medir tiempo de respuesta
            start_time = time.time()
            console.log(f"ğŸ•’ Enviando imagen a OpenAI para anÃ¡lisis...")
            
            response = client.chat.completions.create(
                model=os.getenv("MODEL"),
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": """ğŸ¤ Analiza esta imagen y detecta gestos de manos.
                                
                                Responde ÃšNICAMENTE con un JSON vÃ¡lido en este formato:
                                {
                                    "gesture": "nombre_del_gesto",
                                    "confidence": 85,
                                    "description": "breve descripciÃ³n",
                                    "emoji": "ğŸ‘"
                                }
                                
                                Gestos a detectar:
                                - ğŸ‘ pulgar_arriba
                                - ğŸ‘ pulgar_abajo  
                                - ğŸ‘Œ ok
                                - âœŒï¸ paz
                                - âœŠ puÃ±o
                                - âœ‹ stop
                                - ğŸ‘‹ saludo
                                - ğŸ¤Ÿ rock
                                - ğŸ¤ pellizco
                                - ğŸ‘ aplauso
                                
                                Si no hay gestos claros, usa "gesture": null"""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=200,
                temperature=0.1
            )
            console.log(f"ğŸ•’ Tiempo de respuesta: {time.time() - start_time:.2f} segundos")
            result_text = response.choices[0].message.content.strip()
            
            # Extraer JSON de la respuesta
            json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                console.log(f"ğŸ¤ AnÃ¡lisis completado: {result.get('gesture', 'none')} ({result.get('confidence', 0)}%)")
                return result
            else:
                console.log(f"âš ï¸ No se pudo parsear respuesta de OpenAI: {result_text}")
                return {"gesture": None, "confidence": 0}
                
        except json.JSONDecodeError as e:
            console.log(f"âŒ Error parseando JSON de OpenAI: {e}")
            return {"gesture": None, "confidence": 0}
        except Exception as e:
            console.log(f"âŒ Error con OpenAI Vision API: {e}")
            return {"gesture": None, "confidence": 0}
    
    async def send_gesture_result(self, result):
        """EnvÃ­a el resultado del anÃ¡lisis por el canal de datos"""
        if not self.data_channel:
            console.log(f"âš ï¸ No hay canal de datos para enviar gesto a {self.peer_connection_id}")
            return
            
        try:
            gesture_msg = (
                f"ğŸ¤ IA detectÃ³: {result.get('emoji', 'ğŸ¤')} {result['gesture']} "
                f"({result['confidence']}% confianza) - {result.get('description', '')}"
            )
            
            self.data_channel.send(gesture_msg)
            console.log(f"ğŸ¤ Gesto enviado a {self.peer_connection_id}: {result['gesture']}")
            
        except Exception as e:
            console.log(f"âŒ Error enviando gesto a {self.peer_connection_id}: {e}")
    
    def set_data_channel(self, channel):
        """Establece el canal de datos para enviar resultados"""
        self.data_channel = channel
        console.log(f"ğŸ“¡ Canal de datos configurado para anÃ¡lisis de gestos de {self.peer_connection_id}")
    
    def enable_analysis(self):
        """Activa el anÃ¡lisis de gestos"""
        self.analysis_enabled = True
        console.log(f"ğŸŸ¢ AnÃ¡lisis de gestos activado para {self.peer_connection_id}")
        # Enviar mensaje de prueba inmediatamente
        if self.data_channel:
            test_msg = f"ğŸ¤ Â¡AnÃ¡lisis de gestos iniciado! Canal OK para {self.peer_connection_id}"
            self.data_channel.send(test_msg)
            console.log(f"âœ… Mensaje de prueba enviado: {test_msg}")
    
    def disable_analysis(self):
        """Desactiva el anÃ¡lisis de gestos"""
        self.analysis_enabled = False
        console.log(f"ğŸ”´ AnÃ¡lisis de gestos desactivado para {self.peer_connection_id}")
    
    def set_analysis_interval(self, interval):
        """Cambia el intervalo de anÃ¡lisis"""
        self.analysis_interval = max(1.0, interval)  # MÃ­nimo 1 segundo
        console.log(f"â±ï¸ Intervalo de anÃ¡lisis cambiado a {self.analysis_interval}s para {self.peer_connection_id}")
    
    def set_confidence_threshold(self, threshold):
        """Cambia el umbral de confianza"""
        self.confidence_threshold = max(0, min(100, threshold))  # Entre 0 y 100
        console.log(f"ğŸ¯ Umbral de confianza cambiado a {self.confidence_threshold}% para {self.peer_connection_id}")


class GestureAnalyzer:
    """
    Clase utilitaria para configurar y gestionar el anÃ¡lisis de gestos
    """
    
    @staticmethod
    def create_track(original_track, peer_connection_id, data_channel=None):
        """Crea un track de anÃ¡lisis de gestos"""
        return GestureAnalysisTrack(original_track, peer_connection_id, data_channel)
    
    @staticmethod
    def configure_openai(api_key):
        """Configura la API key de OpenAI"""
        client.api_key = api_key
        console.log("ğŸ”‘ OpenAI API configurada para anÃ¡lisis de gestos")